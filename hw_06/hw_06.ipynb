{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616401d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05db47f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9704, 11)\n",
      "\n",
      "Missing values before filling:\n",
      "engine_displacement      0\n",
      "num_cylinders          482\n",
      "horsepower             708\n",
      "vehicle_weight           0\n",
      "acceleration           930\n",
      "model_year               0\n",
      "origin                   0\n",
      "fuel_type                0\n",
      "drivetrain               0\n",
      "num_doors              502\n",
      "fuel_efficiency_mpg      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_displacement</th>\n",
       "      <th>num_cylinders</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>vehicle_weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>drivetrain</th>\n",
       "      <th>num_doors</th>\n",
       "      <th>fuel_efficiency_mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170</td>\n",
       "      <td>3.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>3413.433759</td>\n",
       "      <td>17.7</td>\n",
       "      <td>2003</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>All-wheel drive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.231729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>5.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3149.664934</td>\n",
       "      <td>17.8</td>\n",
       "      <td>2007</td>\n",
       "      <td>USA</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Front-wheel drive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.688217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3079.038997</td>\n",
       "      <td>15.1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Front-wheel drive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.246341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2542.392402</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2009</td>\n",
       "      <td>USA</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>All-wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.912736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3460.870990</td>\n",
       "      <td>14.4</td>\n",
       "      <td>2009</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>All-wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.488369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engine_displacement  num_cylinders  horsepower  vehicle_weight  \\\n",
       "0                  170            3.0       159.0     3413.433759   \n",
       "1                  130            5.0        97.0     3149.664934   \n",
       "2                  170            NaN        78.0     3079.038997   \n",
       "3                  220            4.0         NaN     2542.392402   \n",
       "4                  210            1.0       140.0     3460.870990   \n",
       "\n",
       "   acceleration  model_year  origin fuel_type         drivetrain  num_doors  \\\n",
       "0          17.7        2003  Europe  Gasoline    All-wheel drive        0.0   \n",
       "1          17.8        2007     USA  Gasoline  Front-wheel drive        0.0   \n",
       "2          15.1        2018  Europe  Gasoline  Front-wheel drive        0.0   \n",
       "3          20.2        2009     USA    Diesel    All-wheel drive        2.0   \n",
       "4          14.4        2009  Europe  Gasoline    All-wheel drive        2.0   \n",
       "\n",
       "   fuel_efficiency_mpg  \n",
       "0            13.231729  \n",
       "1            13.688217  \n",
       "2            14.246341  \n",
       "3            16.912736  \n",
       "4            12.488369  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('car_fuel_efficiency.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nMissing values before filling:\")\n",
    "print(df.isnull().sum())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e7c96e",
   "metadata": {},
   "source": [
    "### Preparing the dataset \n",
    "\n",
    "Preparation:\n",
    "\n",
    "* Fill missing values with zeros.\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1.\n",
    "* Use `DictVectorizer(sparse=True)` to turn the dataframes into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2483e8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after filling:\n",
      "engine_displacement    0\n",
      "num_cylinders          0\n",
      "horsepower             0\n",
      "vehicle_weight         0\n",
      "acceleration           0\n",
      "model_year             0\n",
      "origin                 0\n",
      "fuel_type              0\n",
      "drivetrain             0\n",
      "num_doors              0\n",
      "fuel_efficiency_mpg    0\n",
      "dtype: int64\n",
      "\n",
      "Dataset splits:\n",
      "Train: 5822 samples (60.0%)\n",
      "Validation: 1941 samples (20.0%)\n",
      "Test: 1941 samples (20.0%)\n",
      "\n",
      "Transformed matrices shapes:\n",
      "Train: (5822, 14)\n",
      "Validation: (1941, 14)\n",
      "Test: (1941, 14)\n",
      "\n",
      "Number of features: 14\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fill missing values with zeros\n",
    "df_filled = df.fillna(0)\n",
    "print(f\"Missing values after filling:\")\n",
    "print(df_filled.isnull().sum())\n",
    "\n",
    "# Step 2: Split the data\n",
    "# First, separate features and target\n",
    "# Assuming the target is 'fuel_efficiency_mpg' (last column)\n",
    "X = df_filled.drop('fuel_efficiency_mpg', axis=1)\n",
    "y = df_filled['fuel_efficiency_mpg']\n",
    "\n",
    "# Split into train+val (80%) and test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "# Split train+val into train (60% of total = 75% of train_val) and val (20% of total = 25% of train_val)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=1\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset splits:\")\n",
    "print(f\"Train: {len(X_train)} samples ({len(X_train)/len(df):.1%})\")\n",
    "print(f\"Validation: {len(X_val)} samples ({len(X_val)/len(df):.1%})\")\n",
    "print(f\"Test: {len(X_test)} samples ({len(X_test)/len(df):.1%})\")\n",
    "\n",
    "# Step 3: Convert dataframes to dictionaries\n",
    "train_dicts = X_train.to_dict(orient='records')\n",
    "val_dicts = X_val.to_dict(orient='records')\n",
    "test_dicts = X_test.to_dict(orient='records')\n",
    "\n",
    "# Step 4: Use DictVectorizer to turn dictionaries into matrices\n",
    "dv = DictVectorizer(sparse=True)\n",
    "\n",
    "# Fit on train and transform all sets\n",
    "X_train_transformed = dv.fit_transform(train_dicts)\n",
    "X_val_transformed = dv.transform(val_dicts)\n",
    "X_test_transformed = dv.transform(test_dicts)\n",
    "\n",
    "print(f\"\\nTransformed matrices shapes:\")\n",
    "print(f\"Train: {X_train_transformed.shape}\")\n",
    "print(f\"Validation: {X_val_transformed.shape}\")\n",
    "print(f\"Test: {X_test_transformed.shape}\")\n",
    "print(f\"\\nNumber of features: {len(dv.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785ee65",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the `fuel_efficiency_mpg` variable. \n",
    "\n",
    "* Train a model with `max_depth=1`.\n",
    "\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "\n",
    "* `'vehicle_weight'`\n",
    "* `'model_year'`\n",
    "* `'origin'`\n",
    "* `'fuel_type'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051e4125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature used for splitting: vehicle_weight\n",
      "Feature index: 13\n",
      "\n",
      "Tree structure:\n",
      "Number of nodes: 3\n",
      "Max depth: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Train a decision tree regressor with max_depth=1\n",
    "dt_model = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "dt_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Get the feature used for splitting\n",
    "# For a tree with max_depth=1, there's only one split at the root\n",
    "feature_names = dv.get_feature_names_out()\n",
    "feature_idx = dt_model.tree_.feature[0]  # Get the feature index at the root node\n",
    "split_feature = feature_names[feature_idx]\n",
    "\n",
    "print(f\"Feature used for splitting: {split_feature}\")\n",
    "print(f\"Feature index: {feature_idx}\")\n",
    "print(f\"\\nTree structure:\")\n",
    "print(f\"Number of nodes: {dt_model.tree_.node_count}\")\n",
    "print(f\"Max depth: {dt_model.tree_.max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb42601b",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Train a random forest regressor with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1` (optional - to make training faster)\n",
    "\n",
    "\n",
    "What's the RMSE of this model on the validation data?\n",
    "\n",
    "* 0.045\n",
    "* 0.45\n",
    "* 4.5\n",
    "* 45.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c6c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor RMSE on validation data: 0.4587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=10,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Make predictions on validation data\n",
    "y_val_pred = rf_model.predict(X_val_transformed)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "print(f\"Random Forest Regressor RMSE on validation data: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc954a5",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10.\n",
    "* Set `random_state` to `1`.\n",
    "* Evaluate the model on the validation dataset.\n",
    "\n",
    "\n",
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "Consider 3 decimal places for calculating the answer.\n",
    "\n",
    "- 10\n",
    "- 25\n",
    "- 80\n",
    "- 200\n",
    "\n",
    "If it doesn't stop improving, use the latest iteration number in\n",
    "your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e81f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators | RMSE\n",
      "------------------------------\n",
      "          10 | 0.458662\n",
      "          10 | 0.458662\n",
      "          20 | 0.453680\n",
      "          20 | 0.453680\n",
      "          30 | 0.451172\n",
      "          30 | 0.451172\n",
      "          40 | 0.448357\n",
      "          40 | 0.448357\n",
      "          50 | 0.446179\n",
      "          50 | 0.446179\n",
      "          60 | 0.445300\n",
      "          60 | 0.445300\n",
      "          70 | 0.444674\n",
      "          70 | 0.444674\n",
      "          80 | 0.444994\n",
      "          80 | 0.444994\n",
      "          90 | 0.445205\n",
      "          90 | 0.445205\n",
      "         100 | 0.444896\n",
      "         100 | 0.444896\n",
      "         110 | 0.443718\n",
      "         110 | 0.443718\n",
      "         120 | 0.444101\n",
      "         120 | 0.444101\n",
      "         130 | 0.443773\n",
      "         130 | 0.443773\n",
      "         140 | 0.443502\n",
      "         140 | 0.443502\n",
      "         150 | 0.443020\n",
      "         150 | 0.443020\n",
      "         160 | 0.442789\n",
      "         160 | 0.442789\n",
      "         170 | 0.442894\n",
      "         170 | 0.442894\n",
      "         180 | 0.442548\n",
      "         180 | 0.442548\n",
      "         190 | 0.442607\n",
      "         190 | 0.442607\n",
      "         200 | 0.442520\n",
      "\n",
      "========================================\n",
      "Analysis: When does RMSE stop improving?\n",
      "========================================\n",
      "\n",
      "RMSE stopped improving after n_estimators = 60\n",
      "Best RMSE (3 decimals): 0.445\n",
      "\n",
      "Answer: 60\n",
      "         200 | 0.442520\n",
      "\n",
      "========================================\n",
      "Analysis: When does RMSE stop improving?\n",
      "========================================\n",
      "\n",
      "RMSE stopped improving after n_estimators = 60\n",
      "Best RMSE (3 decimals): 0.445\n",
      "\n",
      "Answer: 60\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Experiment with n_estimators from 10 to 200 with step 10\n",
    "n_estimators_values = range(10, 201, 10)\n",
    "rmse_scores = []\n",
    "\n",
    "print(\"n_estimators | RMSE\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for n_est in n_estimators_values:\n",
    "    # Train Random Forest with current n_estimators\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_est,\n",
    "        random_state=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train_transformed, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = rf_model.predict(X_val_transformed)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    rmse_scores.append((n_est, rmse))\n",
    "    \n",
    "    print(f\"{n_est:12d} | {rmse:.6f}\")\n",
    "\n",
    "# Find when RMSE stops improving (rounded to 3 decimal places)\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Analysis: When does RMSE stop improving?\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "min_rmse = float('inf')\n",
    "stop_improving_at = None\n",
    "\n",
    "for n_est, rmse in rmse_scores:\n",
    "    rmse_rounded = round(rmse, 3)\n",
    "    \n",
    "    if rmse_rounded < round(min_rmse, 3):\n",
    "        min_rmse = rmse\n",
    "        stop_improving_at = n_est\n",
    "    else:\n",
    "        # RMSE stopped improving (considering 3 decimal places)\n",
    "        if stop_improving_at is not None:\n",
    "            print(f\"\\nRMSE stopped improving after n_estimators = {stop_improving_at}\")\n",
    "            print(f\"Best RMSE (3 decimals): {round(min_rmse, 3):.3f}\")\n",
    "            break\n",
    "else:\n",
    "    # If we reach here, RMSE kept improving until the end\n",
    "    print(f\"\\nRMSE kept improving until n_estimators = {rmse_scores[-1][0]}\")\n",
    "    print(f\"Final RMSE (3 decimals): {round(rmse_scores[-1][1], 3):.3f}\")\n",
    "    stop_improving_at = rmse_scores[-1][0]\n",
    "\n",
    "print(f\"\\nAnswer: {stop_improving_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f436173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Analysis:\n",
      "==================================================\n",
      "Minimum RMSE (3 decimals): 0.443\n",
      "n_estimators values that achieve minimum: [150, 160, 170, 180, 190, 200]\n",
      "\n",
      "First n_estimators where minimum is reached: 150\n",
      "\n",
      "==================================================\n",
      "Checking when RMSE stops decreasing:\n",
      "==================================================\n",
      "n= 10: RMSE=0.459 ⬇ improved\n",
      "n= 20: RMSE=0.454 ⬇ improved\n",
      "n= 30: RMSE=0.451 ⬇ improved\n",
      "n= 40: RMSE=0.448 ⬇ improved\n",
      "n= 50: RMSE=0.446 ⬇ improved\n",
      "n= 60: RMSE=0.445 ⬇ improved\n",
      "n= 70: RMSE=0.445 → same\n",
      "n= 80: RMSE=0.445 → same\n",
      "n= 90: RMSE=0.445 → same\n",
      "n=100: RMSE=0.445 → same\n",
      "n=110: RMSE=0.444 ⬇ improved\n",
      "n=120: RMSE=0.444 → same\n",
      "n=130: RMSE=0.444 → same\n",
      "n=140: RMSE=0.444 → same\n",
      "n=150: RMSE=0.443 ⬇ improved\n",
      "n=160: RMSE=0.443 → same\n",
      "n=170: RMSE=0.443 → same\n",
      "n=180: RMSE=0.443 → same\n",
      "n=190: RMSE=0.443 → same\n",
      "n=200: RMSE=0.443 → same\n",
      "\n",
      "==================================================\n",
      "Last improvement occurred at n_estimators = 150\n"
     ]
    }
   ],
   "source": [
    "# Let's analyze the results more carefully\n",
    "# Looking at when the minimum RMSE (at 3 decimal places) is first achieved\n",
    "\n",
    "print(\"Detailed Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Extract RMSE values rounded to 3 decimals\n",
    "rmse_rounded = [(n_est, round(rmse, 3)) for n_est, rmse in rmse_scores]\n",
    "\n",
    "# Find the minimum RMSE (3 decimals)\n",
    "min_rmse_3dec = min(rmse for _, rmse in rmse_rounded)\n",
    "print(f\"Minimum RMSE (3 decimals): {min_rmse_3dec:.3f}\")\n",
    "\n",
    "# Find all n_estimators that achieve this minimum\n",
    "optimal_n_estimators = [n_est for n_est, rmse in rmse_rounded if rmse == min_rmse_3dec]\n",
    "print(f\"n_estimators values that achieve minimum: {optimal_n_estimators}\")\n",
    "\n",
    "# Find the first occurrence of this minimum\n",
    "first_optimal = optimal_n_estimators[0]\n",
    "print(f\"\\nFirst n_estimators where minimum is reached: {first_optimal}\")\n",
    "\n",
    "# Check when RMSE stops decreasing consistently\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Checking when RMSE stops decreasing:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "prev_rmse = float('inf')\n",
    "for n_est, rmse in rmse_rounded:\n",
    "    status = \"\"\n",
    "    if rmse < prev_rmse:\n",
    "        status = \"⬇ improved\"\n",
    "    elif rmse > prev_rmse:\n",
    "        status = \"⬆ increased\"\n",
    "    else:\n",
    "        status = \"→ same\"\n",
    "    print(f\"n={n_est:3d}: RMSE={rmse:.3f} {status}\")\n",
    "    prev_rmse = rmse\n",
    "\n",
    "# Find the last point of improvement\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "last_improvement = None\n",
    "for i in range(len(rmse_rounded) - 1):\n",
    "    current_rmse = rmse_rounded[i][1]\n",
    "    next_rmse = rmse_rounded[i + 1][1]\n",
    "    if next_rmse < current_rmse:\n",
    "        last_improvement = rmse_rounded[i + 1][0]\n",
    "\n",
    "if last_improvement:\n",
    "    print(f\"Last improvement occurred at n_estimators = {last_improvement}\")\n",
    "else:\n",
    "    print(\"RMSE did not improve after n_estimators = 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb6fb0a",
   "metadata": {},
   "source": [
    "### Answer to Question 3\n",
    "\n",
    "Based on the experiment with `n_estimators` from 10 to 200 (step 10):\n",
    "\n",
    "- **RMSE continues to improve until n_estimators = 150**\n",
    "- After 150, the RMSE remains at 0.443 (when rounded to 3 decimal places)\n",
    "- The last improvement occurred at **n_estimators = 150**\n",
    "\n",
    "Since the question asks \"after which value does RMSE stop improving\", and considering 3 decimal places:\n",
    "- After n_estimators = 150, there is no further improvement\n",
    "- From the given options (10, 25, 80, 200), the closest interpretation is:\n",
    "  - It doesn't match 10, 25, or 80 (RMSE was still improving at these points)\n",
    "  - It continues improving beyond 80 but stops improving after 150\n",
    "  \n",
    "However, looking at the available options and the instruction \"If it doesn't stop improving, use the latest iteration number\", since RMSE does stop improving at some point (150) but this isn't in the options, and the last test was 200, the answer should be **200** (the latest iteration number).\n",
    "\n",
    "But if we interpret it as \"stops showing significant improvement\", we could argue:\n",
    "- At **80**, RMSE = 0.445 (and stays around 0.444-0.445 for many iterations)\n",
    "- This is where the improvement becomes very marginal\n",
    "\n",
    "**Answer: 80** (where the rate of improvement becomes negligible for several iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfdecf2",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values,\n",
    "  * try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "  * calculate the mean RMSE \n",
    "* Fix the random seed: `random_state=1`\n",
    "\n",
    "\n",
    "What's the best `max_depth`, using the mean RMSE?\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ae8b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=10: mean RMSE=0.44188\n",
      "max_depth=15: mean RMSE=0.44562\n",
      "max_depth=15: mean RMSE=0.44562\n",
      "max_depth=20: mean RMSE=0.44568\n",
      "max_depth=20: mean RMSE=0.44568\n",
      "max_depth=25: mean RMSE=0.44570\n",
      "\n",
      "Best max_depth: 10 (mean RMSE=0.44188)\n",
      "max_depth=25: mean RMSE=0.44570\n",
      "\n",
      "Best max_depth: 10 (mean RMSE=0.44188)\n"
     ]
    }
   ],
   "source": [
    "# Question 4: Grid search for best max_depth using mean RMSE\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "max_depth_values = [10, 15, 20, 25]\n",
    "n_estimators_values = range(10, 201, 10)\n",
    "mean_rmse_per_depth = {}\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    rmses = []\n",
    "    for n_est in n_estimators_values:\n",
    "        rf = RandomForestRegressor(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=max_depth,\n",
    "            random_state=1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        rf.fit(X_train_transformed, y_train)\n",
    "        y_val_pred = rf.predict(X_val_transformed)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "        rmses.append(rmse)\n",
    "    mean_rmse = np.mean(rmses)\n",
    "    mean_rmse_per_depth[max_depth] = mean_rmse\n",
    "    print(f\"max_depth={max_depth}: mean RMSE={mean_rmse:.5f}\")\n",
    "\n",
    "best_depth = min(mean_rmse_per_depth, key=mean_rmse_per_depth.get)\n",
    "print(f\"\\nBest max_depth: {best_depth} (mean RMSE={mean_rmse_per_depth[best_depth]:.5f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ec31b",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorithm, it finds the best split. \n",
    "When doing it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the important features for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the\n",
    "[`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_)\n",
    "field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parameters:\n",
    "  * `n_estimators=10`,\n",
    "  * `max_depth=20`,\n",
    "  * `random_state=1`,\n",
    "  * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model\n",
    "\n",
    "\n",
    "What's the most important feature (among these 4)? \n",
    "\n",
    "* `vehicle_weight`\n",
    "*\t`horsepower`\n",
    "* `acceleration`\n",
    "* `engine_displacement`\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc7fc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature  importance\n",
      "13       vehicle_weight    0.959153\n",
      "6            horsepower    0.016066\n",
      "0          acceleration    0.011490\n",
      "3   engine_displacement    0.003279\n",
      "\n",
      "Most important feature: vehicle_weight\n"
     ]
    }
   ],
   "source": [
    "# Question 5: Feature Importance for RandomForestRegressor\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=10,\n",
    "    max_depth=20,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "feature_names = dv.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Filter for the 4 features of interest\n",
    "features_of_interest = [\n",
    "    'vehicle_weight',\n",
    "    'horsepower',\n",
    "    'acceleration',\n",
    "    'engine_displacement'\n",
    "]\n",
    "\n",
    "importances_df_interest = importances_df[importances_df['feature'].isin(features_of_interest)]\n",
    "importances_df_interest = importances_df_interest.sort_values(by='importance', ascending=False)\n",
    "print(importances_df_interest)\n",
    "\n",
    "# Most important feature:\n",
    "most_important = importances_df_interest.iloc[0]['feature']\n",
    "print(f\"\\nMost important feature: {most_important}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e52dc05",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter:\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```\n",
    "\n",
    "Now change `eta` from `0.3` to `0.1`.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* Both give equal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b53d18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.81393\tval-rmse:1.85444\n",
      "[10]\ttrain-rmse:0.37115\tval-rmse:0.43896\n",
      "[20]\ttrain-rmse:0.33553\tval-rmse:0.43376\n",
      "[30]\ttrain-rmse:0.31475\tval-rmse:0.43752\n",
      "[40]\ttrain-rmse:0.30202\tval-rmse:0.43968\n",
      "[50]\ttrain-rmse:0.28456\tval-rmse:0.44140\n",
      "[60]\ttrain-rmse:0.26768\tval-rmse:0.44290\n",
      "[70]\ttrain-rmse:0.25489\tval-rmse:0.44531\n",
      "[80]\ttrain-rmse:0.24254\tval-rmse:0.44689\n",
      "[90]\ttrain-rmse:0.23193\tval-rmse:0.44839\n",
      "[99]\ttrain-rmse:0.21950\tval-rmse:0.45018\n",
      "\n",
      "RMSE with eta=0.3: 0.4502\n",
      "[0]\ttrain-rmse:2.28944\tval-rmse:2.34561\n",
      "[10]\ttrain-rmse:0.91008\tval-rmse:0.94062\n",
      "[20]\ttrain-rmse:0.48983\tval-rmse:0.53064\n",
      "[30]\ttrain-rmse:0.38342\tval-rmse:0.44289\n",
      "[40]\ttrain-rmse:0.35343\tval-rmse:0.42746\n",
      "[50]\ttrain-rmse:0.33998\tval-rmse:0.42498\n",
      "[60]\ttrain-rmse:0.33054\tval-rmse:0.42456\n",
      "[70]\ttrain-rmse:0.32202\tval-rmse:0.42503\n",
      "[80]\ttrain-rmse:0.31667\tval-rmse:0.42563\n",
      "[90]\ttrain-rmse:0.31059\tval-rmse:0.42586\n",
      "[99]\ttrain-rmse:0.30419\tval-rmse:0.42623\n",
      "\n",
      "RMSE with eta=0.1: 0.4262\n",
      "\n",
      "==================================================\n",
      "Comparison:\n",
      "eta=0.3: RMSE = 0.4502\n",
      "eta=0.1: RMSE = 0.4262\n",
      "\n",
      "Answer: 0.1 leads to better RMSE\n"
     ]
    }
   ],
   "source": [
    "# Q6: XGBoost tuning eta\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# Prepare DMatrix for train and validation\n",
    "features = dv.transform(train_dicts)\n",
    "features_val = dv.transform(val_dicts)\n",
    "dtrain = xgb.DMatrix(features, label=y_train)\n",
    "dval = xgb.DMatrix(features_val, label=y_val)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model_03 = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, verbose_eval=10)\n",
    "\n",
    "# Predict and calculate RMSE for eta=0.3\n",
    "from sklearn.metrics import mean_squared_error\n",
    "val_pred_03 = model_03.predict(dval)\n",
    "rmse_03 = np.sqrt(mean_squared_error(y_val, val_pred_03))\n",
    "print(f'\\nRMSE with eta=0.3: {rmse_03:.4f}')\n",
    "\n",
    "# Now try eta=0.1\n",
    "xgb_params[\"eta\"] = 0.1\n",
    "model_01 = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, verbose_eval=10)\n",
    "val_pred_01 = model_01.predict(dval)\n",
    "rmse_01 = np.sqrt(mean_squared_error(y_val, val_pred_01))\n",
    "print(f'\\nRMSE with eta=0.1: {rmse_01:.4f}')\n",
    "\n",
    "# Compare results\n",
    "print(f'\\n{\"=\"*50}')\n",
    "print(f'Comparison:')\n",
    "print(f'eta=0.3: RMSE = {rmse_03:.4f}')\n",
    "print(f'eta=0.1: RMSE = {rmse_01:.4f}')\n",
    "if rmse_03 < rmse_01:\n",
    "    print(f'\\nAnswer: 0.3 leads to better RMSE')\n",
    "elif rmse_01 < rmse_03:\n",
    "    print(f'\\nAnswer: 0.1 leads to better RMSE')\n",
    "else:\n",
    "    print(f'\\nAnswer: Both give equal value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
